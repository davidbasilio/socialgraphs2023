{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This week is all about working with data. I'm not going to lie to you. This part might be frustrating - but frustration is an integral part of learning. Real data is almost always messy & difficult ... and learning to deal with that fact, is a key part of being a data scientist. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enough about the process, let's get to the content. \n",
    "\n",
    "![Text](https://wallpapers.com/images/high/cool-rapper-zs7xat10uqylszmy.webp \"Great image choice, Jonas\")\n",
    "\n",
    "Today, we will use network science and Wikipedia to learn about the relationships of **[West Coast](https://en.wikipedia.org/wiki/Category:West_Coast_hip_hop_musicians)** and **[East coast](https://en.wikipedia.org/wiki/Category:East_Coast_hip_hop_musicians)** rappers. \n",
    "\n",
    "To create the network, we will download the Wikipedia pages for all rappers from each coast. Next, we will create the network of the pages that link to each other. Since wikipedia pages link to each other. So [Snoop Dogg](https://en.wikipedia.org/wiki/Snoop_Dogg) links to [Dr. Dre](https://en.wikipedia.org/wiki/Dr._Dre), for example.\n",
    "\n",
    "Next time, we'll use our network skills (as well as new ones) to understand that network. Further down the line, we'll use natural language processing to understand the text displayed on those pages.\n",
    "\n",
    "But for today, the tasks are\n",
    "\n",
    "* Learn about regular expressions\n",
    "* Learn about Pandas dataframes\n",
    "* Download and store (for later use) all the rapper-pages from Wikipedia\n",
    "* Extract all the internal wikipedia-links that connect the rappers on wikipedia\n",
    "* Generate the network of rappers on wikipedia. \n",
    "* Calculate some simple network statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Guide to Week 4 (not to be missed)\n",
    "\n",
    "Today I talk about \n",
    "\n",
    "* Results of the user satisfaction questionnaire\n",
    "* Assignment 1\n",
    "* Today's exercises\n",
    "\n",
    "> * ***Video lecture*** Guide to week 4 https://www.dropbox.com/scl/fi/b760tkugfrnm9kca1apnb/GuideToWeek4.mp4?rlkey=r7y6pijkafc9zn5tcz1cmj8dg&dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Prelude: Regular expressions\n",
    "\n",
    "Before we get started, we have to get a little head start on the _Natural Language Processing_ part of the class. This is a new direction for us, up to now, we've mostly been doing math-y stuff with Python, but today, we're going to be using Python to work through a text. The central thing we need to be able to do today, is to extract internal wikipedia links. And for that we need regular expressions.\n",
    "\n",
    "> _Exercises_: Regular expressions round 1\\.\n",
    "> \n",
    "> * Read [**this tutorial**](https://developers.google.com/edu/python/regular-expressions) to form an overview of regular expressions. This is important to understand the content of the tutorial (also very useful later), so you may actually want to work through the examples.\n",
    "> * Now, explain in your own words: what are regular expressions?   \n",
    "> Regular expressions are a way to locate a specific pattern in text. They use a combination of characters and symbols. These are a way to extract information from a text.\n",
    "> * Provide an example of a regex to match 4 digits numbers (by this, I mean precisely 4 digits, you should not match any part of numbers with e.g. 5 digits). In your notebook, use `findall` to show that your regex works on this [test-text](https://raw.githubusercontent.com/SocialComplexityLab/socialgraphs2020/master/files/regex_exercise.txt). **Hint**: a great place to test out regular expressions is: https://regex101.com.\n",
    "> * Provide an example of a regex to match words starting with \"super\". Show that it works on the [test-text](https://raw.githubusercontent.com/SocialComplexityLab/socialgraphs2020/master/files/regex_exercise.txt).\n",
    "> \n",
    "\n",
    "Finally, we need to figure out how how to match internal wiki links. Wiki links come in two flavors. They're always enclosed in double square brackets, e.g. `[[wiki-link]]` and can either occur like this:\n",
    "\n",
    "    ... some text [[Aristotle]] some more text ...\n",
    "\n",
    "which links to the page [`https://en.wikipedia.org/wiki/Aristotle`](https://en.wikipedia.org/wiki/Aristotle). \n",
    "\n",
    "The second flavor has two parts, so that links can handle spaces and other more fancy forms of references, here's an example:\n",
    "\n",
    "    ... some text [[John_McCain|John McCain]] some more text ...\n",
    "\n",
    "which links to the page [`https://en.wikipedia.org/wiki/John_McCain`](https://en.wikipedia.org/wiki/Eudemus_of_Rhodes). Now it's your turn.\n",
    "\n",
    "> _Exercise_: Regular expressions round 2\\. Show that you can extract the wiki-links from the [test-text](https://raw.githubusercontent.com/SocialComplexityLab/socialgraphs2020/master/files/regex_exercise.txt). Perhaps you can find inspiration on stack overflow or similar. **Hint**: Try to solve this exercise on your own (that's what you will get the most out of - learning wise), but if you get stuck ... you will find the solution in one of the video lectures below.\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 1234 ', ' 9999 ']\n",
      "['superpolaroid', 'supertaxidermy', 'superbeer']\n",
      "['[[drinking vinegar]]', '[[gentrify]]', '[[hashtag]]', '[[Bicycle|Bicycle(two-wheeled type)]]', '[[Pitchfork|Pitchfork Magazine]]']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open('week3_ex1.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "    digits = re.findall(r'\\s\\d\\d\\d\\d\\s', text)\n",
    "    super = re.findall(r'\\bsuper\\w*', text)\n",
    "    wiki = re.findall(r'\\[\\[[^\\]]+\\]\\]', text)\n",
    "    print(digits)\n",
    "    print(super)\n",
    "    print(wiki)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelude part 2: Pandas DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, we will also learn a bit about [pandas dataframes](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html), a very user-friendly data structure that you can use to manipulate tabular data. Pandas dataframes are implemented within the [pandas package] (https://pandas.pydata.org/).\n",
    "\n",
    "Pandas dataframes should be intuitive to use. **We suggest you to go through the [10 minutes to Pandas tutorial](https://pandas.pydata.org/pandas-docs/version/0.22/10min.html#min) to learn what you need to solve the next exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part A: Download the Wikipedia pages of rappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to download all of the pages of the characters. Use your experience with APIs from Week 1\\. To get started, I **strongly** recommend that you revisit the [**APIs note book**](https://github.com/SocialComplexityLab/socialgraphs2023/blob/main/files/API_check.ipynb) from that week - it contains lots of useful tips on this specific activity (yes, I had planned this all along!). ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you could first download the names of all the rappers, starting from \n",
    "\n",
    "* https://en.wikipedia.org/wiki/Category:West_Coast_hip_hop_musicians\n",
    "* https://en.wikipedia.org/wiki/Category:East_Coast_hip_hop_musicians\n",
    "\n",
    "But this might result in so much pain and suffering that I will not make you do that (although you are very much welcome to try!). Instead, you can download all the names, nice and clean, here (it might still include couple of *noisy* links, but should be fine in 95% of records):\n",
    " \n",
    "* **[West coast List](https://github.com/SocialComplexityLab/socialgraphs2023/blob/main/files/WestCoastRappers.csv)**\n",
    "* **[East coast List](https://github.com/SocialComplexityLab/socialgraphs2023/blob/main/files/EastCoastRappers.csv)**\n",
    "\n",
    "The files contain the wiki-link of all rappers in the two lists above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "df_east = pd.read_csv('data/EastCoastRappers.csv', index_col=0)\n",
    "df_west = pd.read_csv('data/WestCoastRappers.csv', index_col=0)\n",
    "df = pd.concat([df_east, df_west], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikipediaPageName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ix9ine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9th Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22Gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38 Spesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 45 King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Young L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Yukmouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Arif Zahir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Zealous1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Asaiah Ziv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    WikipediaPageName\n",
       "0             6ix9ine\n",
       "1          9th Prince\n",
       "2                22Gz\n",
       "3            38 Spesh\n",
       "4         The 45 King\n",
       "..                ...\n",
       "796           Young L\n",
       "797          Yukmouth\n",
       "798        Arif Zahir\n",
       "799          Zealous1\n",
       "800        Asaiah Ziv\n",
       "\n",
       "[801 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = {key : None for key in df['WikipediaPageName']}\n",
    "for key in df['WikipediaPageName']:\n",
    "    try :\n",
    "        baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\": \"revisions\",\n",
    "            \"rvprop\": \"content\",\n",
    "            \"format\": \"json\",\n",
    "            \"titles\": key.replace(' ', '_')\n",
    "        }\n",
    "        wikitext = requests.get(baseurl, params=params)\n",
    "        wikijson = wikitext.json()\n",
    "        wiki[key] = wikijson\n",
    "    except UnicodeEncodeError as e:\n",
    "        print(f'UnicodeEncodeError: {e} in {key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{short description|American rapper from California (born 1987)}}\\n{{Infobox musical artist\\n| name            = 03 Greedo\\n| birth_name      = Jason Jamal Jackson\\n| birth_date      = {{Birth date and age|mf=yes|1987|7|26}}\\n| alias           = Greedy Giddy\\n| birth_place     = [[Los Angeles]], [[California]], [[U.S.]]<ref name=\"complex interview\">{{cite web|url=http://www.complex.com/music/2018/03/03-greedo-wolf-of-grape-street-interview\\n|title=03 Greedo Raps More—and Better—Than You|publisher=Complex |date=2018-03-09|access-date=2018-04-22}}</ref>\\n| genre           = {{hlist|[[West Coast hip hop|West Coast hip-hop]]|[[Trap music (hip hop)|trap]]|[[Hip hop music|hip hop]]}}\\n| occupation      = {{hlist|Rapper|singer|songwriter|producer}}\\n| instrument      = {{hlist|Vocals}}\\n| years_active    = 2010–present\\n| label           = {{hlist|Golden Grenade Empire|[[Todd Moscowitz|Alamo]]}}\\n| website         = {{URL|https://soundcloud.com/03greedo}}\\n}}\\n\\n\\'\\'\\'Jason Jamal Jackson\\'\\'\\' (born July 26, 1987), known professionally as \\'\\'\\'03 Greedo\\'\\'\\',<ref name=\":0\">{{Cite news|url=https://noisey.vice.com/en_us/article/43q5zg/the-impossible-tale-of-03-greedo-the-future-of-west-coast-rap|title=The Impossible Tale of 03 Greedo, the Future of West Coast Rap|date=2018-01-16|work=Noisey|access-date=2018-04-23|language=en-us}}</ref> is an American [[Rapping|rapper]], singer, songwriter and producer from the [[Watts, Los Angeles|Watts]] neighborhood of the city of [[Los Angeles, California]].<ref name=\"complex interview\" /> He began to gain recognition for his \\'\\'Purple Summer\\'\\' mixtape series that started in 2016.<ref>{{Cite web|url=https://pitchfork.com/reviews/albums/03-greedo-the-wolf-of-grape-street/|title=03 Greedo: The Wolf of Grape Street Album Review |website=pitchfork.com|language=en|access-date=2018-04-23}}</ref> He then saw more mainstream attention with the release of his mixtape, \\'\\'The Wolf of [[Grape Street Watts Crips|Grape Street]]\\'\\'. His debut studio album, \\'\\'God Level\\'\\', was released on June 26, 2018.<ref>{{Cite news|url=http://www.thefader.com/2018/06/26/03-greedo-god-level-album-premiere|title=03 Greedo\\'s \\'\\'God Level\\'\\' album is here|work=The Fader|access-date=2018-10-04|language=en}}</ref>\\n\\nIn July 2018, he was sentenced to 20 years in prison on drug trafficking and possession of a firearm charges. On January 8, 2023, it was announced that 03 Greedo would be released on January 12.<ref name=\":2\">{{Cite news|url=http://www.thefader.com/2018/04/30/03-greedo-prison-sentence|title=03 Greedo has been sentenced to 20 years in prison #free03 |work=The Fader|access-date=2018-05-17|language=en}}</ref> Despite being in prison, he has remained prolific in releasing music.<ref name=\"Load\">{{cite web |url=https://www.hotnewhiphop.com/03-greedo-and-key-glock-drop-off-drip-keep-going-new-song.1988236.html? |title=03 Greedo & Key Glock Drop Off \"Drip Keep Going\" |work=HotNewHipHop |date=August 12, 2020 |access-date=August 12, 2020|author=Findlay, Mitch}}</ref>\\n\\n== Early life ==\\nJason Jamal Jackson was born in [[West Los Angeles, California]], on July 26, 1987, to Michael and Lisa Jackson. In late 1988, when Jackson was only a year old, his father was killed in a motorcycle accident. This was shortly after his parents had purchased their home in [[Gardena, California]], where Jackson was raised along with his brother and sister. He was the youngest of the three. Prior to his father\\'s death, he and his family lived in Los Angeles near the Chester Washington Golf Course. As a toddler, he had a series of ear infections which resulted in a [[tympanostomy tube]].<ref name=\":1\">{{Cite news|url=http://www.thefader.com/2018/03/06/03-greedo-first-night-out-purple-summer-la-interview|title=How 03 Greedo became a living legend|work=The Fader|access-date=2018-04-23|language=en}}</ref> At age 17, Jackson was expecting a baby with his high school girlfriend. He worked various retail jobs and sold his own beats in anticipation of supporting his only child – a daughter who was born after they turned 18<ref name=\":0\" /> – and her mother. Soon after, he began to sell drugs to support his family. Jackson was kicked out of his home by his mother after she grew tired of his disrespectful behavior. He stayed with various friends, including his daughter\\'s mother; he also spent a period of time homeless.<ref name=\":0\" /> He  moved to the Watts area of Los Angeles and later settled in [[Jordan Downs|the Jordan Downs Housing Projects]] in [[Watts, Los Angeles|Watts]].<ref name=\":0\" />\\n\\n== Career ==\\nJackson initially used the alias Greedy Giddy, under which he self-produced six mixtapes including the \\'\\'Bipolar\\'\\' series, \\'\\'Everybody Weak\\'\\', and \\'\\'Money, Powder, Regrets\\'\\'.<ref name=\":0\" /> His early career was heavily influenced by [[Southern hip hop|Southern rap]] with auto-tuned harmonics and melodic trap instrumentals. This early work is fragmented with a handful of recordings on DatPiff, YouTube, and Tumblr.<ref name=\":0\" />\\n\\nAs Greedy Giddy, Jackson released numerous tracks to SoundCloud between 2014 and 2016. In 2016, Jackson changed his name to 03 Greedo and self-produced two mixtapes, \\'\\'Purple Summer\\'\\' and \\'\\'Purple Summer 2: Sun Don’t Shine\\'\\'. He also started his own label, Golden Grenade Empire, in 2016. In 2017 Jackson produced three mixtapes, \\'\\'Purple Summer 03: Purple Hearted Soldier\\'\\', \\'\\'First Night Out\\'\\', and \\'\\'Money Changes Everything\\'\\'.<ref name=\":1\" />\\nCo Signed Drop 3 Hot Young and coming rapper out of Tulsa Oklahoma\\nIn 2017 Jackson signed with [[Todd Moscowitz]]\\'s Alamo Records for over a million-dollar contract.<ref name=\":0\" /> He released \\'\\'The Wolf of Grape Street\\'\\' in March 2018 on Alamo. A follow-up, \\'\\'God Level,\\'\\' <ref name=\"complex interview\" /> was released in late June of the same year.\\n\\nThe night before his sentencing, Jackson met with fellow rappers [[Smokepurpp]], [[Lil Pump]], [[Lil Uzi Vert]] and [[Desto Dubb]] to record material produced by Fizzle.<ref>{{Cite web|url=https://soundcloud.com/destodubb/bankteller-ft-03-greedo-lil-pump-lil-uzi-vert-smokepurpp-prod-fizzle|title=Bankteller ft. 03 Greedo, Lil Pump, Lil Uzi Vert & Smokepurpp (prod fizzle)|website=SoundCloud|language=en|access-date=2019-09-21}}</ref> One of these tracks, \"Bankteller,\" was simultaneously released on September 25, 2018, by Desto Dubb (through his SoundCloud page), Uprise, as well as [[Adam Grandmaison|No Jumper]] (both through YouTube) and has since gained some traction through promotion by Desto Dubb, [[Lil Pump]], and [[Adam Grandmaison|Adam22]].<ref>[https://noisey.vice.com/amp/en_us/article/gyn5mj/damn-lil-uzi-vert-03-greedo-lil-pump-and-smokepurpp-are-all-on-one-song Reliable Account of Rap Industry] - Noted Culturally Aware Source</ref><ref>[https://www.complex.com/music/2018/09/lil-uzi-vert-03-greedo-lil-pump-smokepurpp-desto-dubb-bankteller Reliable Account of Rap Pop Culture] - Hip-Hop Insider</ref><ref>[https://hypebeast.com/2018/9/desto-dubb-bank-teller-03-greedo-lil-pump-lil-uzi-vert-smokepurpp-stream?amp=1 Account of Trappers] - Noted Pop Culture Source</ref><ref>[https://www.billboard.com/amp/articles/columns/hip-hop/8477063/desto-dubb-bankteller Reliable Account of Music Industry] - Relevant Musical Source</ref><ref>[https://www.thefader.com/2018/09/26/03-greedo-lil-uzi-vert-lil-pump-smokepurpp-bankteller/amp Reliable Account of Musical Industry] - Noted Culturally Aware Youth Source</ref>  Before turning himself into authorities, Jackson promised to make a vault of 30 albums, he then said he had finished over 3,000 songs before beginning his 20-year sentence.<ref>{{cite web |last1=McKinney |first1=Jessica |title=How 03 Greedo Prepared a Vault of Over 3,000 Songs Before His 20-Year Prison Sentence |url=https://www.complex.com/music/2019/08/03-greedo-interview-days-before-prison-sentence-3000-songs |website=Complex |access-date=13 March 2020}}</ref>\\n\\nOn June 22, 2018, Jackson remixed his single \"Never Bend\" with fellow rapper [[Lil Uzi Vert]].<ref>{{Cite news|url=http://www.thefader.com/2018/06/22/03-greedo-never-bend-remix-lil-uzi|title=03 Greedo shares \"Never Bend\" remix featuring Lil Uzi Vert|work=The Fader|access-date=2018-09-05|language=en}}</ref>\\n\\nOn July 5, 2019, Jackson and [[Blink-182]] drummer [[Travis Barker]] released a joint EP \\'\\'Meet the Drummers\\'\\'.<ref name=\"Meet the Drummers EP\">{{cite web |title=03 Greedo and Travis Barker Announce Meet the Drummers EP |url=https://pitchfork.com/news/03-greedo-and-travis-barker-announce-meet-the-drummers-ep-share-new-song-listen/ |website=pitchfork.com |date=3 July 2019 |access-date=14 August 2019}}</ref>\\n\\nIn September 2019, Jackson and [[Kenny Beats]] released a new album titled \\'\\'Netflix & Deal\\'\\'.\\n\\n03 Greedo\\'s eighth album, \\'\\'Load It Up Vol 01\\'\\', was released on August 14, 2020. It was preceded by the single, \"Drip Keep Going\", featuring [[Key Glock]].<ref name=\"Load\" />\\n\\nOn February 4, 2022, Jackson released a new single titled \"Pourin\" featuring Mike Free and BlueBucksClan on [[Alamo Records]] via [[Sony Music Entertainment]].<ref>{{Cite web|url=https://www.thehypemagazine.com/2022/02/03-greedo-pourin-ft-bluebucksclan/|title = 03 Greedo – \"Pourin\" ft. BlueBucksClan| date=9 February 2022 }}</ref> Almost a year later, on January 9, 2023, Jackson released the Mike Free produced mixtape \\'\\'Free 03\\'\\', which included the single.<ref>{{Cite web|url=http://www.thefader.com/2023/01/09/03-greedo-free-03-mixtape|title = 03 Greedo drops Free 03 mixtape|date=9 January 2023}}</ref>\\n\\nAfter being released from prison in early 2023 he started recording lots of new songs and on March 17, 2023, he released Bacc Like I Never Left, the first of two singles he released prior to Halfway There, his fifth studio album, on March 24, 2023.<ref>{{cite web|url=https://www.complex.com/music/03-greedo-halfway-there-mixtape|title = 03 Greedo releases fifth studio album, first one after being in prison for five years|date=24 March 2023}}</ref>\\n\\n==Personal life==\\nOne of Jackson\\'s most distinctive features is the term \"Living Legend\" tattooed on his face.<ref name=\":1\" />\\n\\nIn 2016, Jackson was arrested in Texas on drug trafficking and possession of a firearm charges. According to a police report, Potter County Sheriff deputies forced open his car\\'s trunk after claiming to smell [[Cannabis (drug)|cannabis]] and found \"four pounds of [[methamphetamine]] and two stolen pistols.\"<ref>{{Cite news|url=https://www.passionweiss.com/2018/04/29/03-greedo-watts-legend/|title=Living Legend: Why 03 Greedo Matters|date=2018-04-30|work=Passion of the Weiss|access-date=2018-05-17|language=en-US}}</ref> Jackson originally faced a  sentence of 300 years for the charges. However, he  eventually took a plea deal and was sentenced to 20 years in prison, though he could be released in five years with good behavior.<ref name=\":2\" /> He began his sentence in the summer of 2018 and was imprisoned at the Middleton Unit. In 2022, he was moved to the William R. Boyd Unit.<ref>[https://inmate.tdcj.texas.gov/InmateSearch/viewDetail.action?sid=16298801 Texas Offender Information Details]</ref> He was initially set to become eligible for parole in July 2020, but this was denied in 2020 and 2021. Jackson was granted parole release in June 2022 upon completion of a prerelease program and on January 8, 2023, it was confirmed that Jackson was set to be released on January 12, 2023.<ref>[https://inmate.tdcj.texas.gov/InmateSearch/reviewDetail.action?sid=16298801&tdcj=02208297&fullName=JACKSON%2CJASON+JAMAL Texas Offender Information Details]</ref>\\n\\n== Discography ==\\n=== Studio albums ===\\n*\\'\\'God Level\\'\\' (2018)\\n*\\'\\'Still Summer In the Projects\\'\\' (2019)\\n*\\'\\'Netflix & Deal\\'\\' (with [[Kenny Beats]]) (2019)\\n*\\'\\'Load It Up Vol 01\\'\\' (with Ron-RonTheProducer) (2020)\\n* \\'\\'Halfway There\\'\\' (2023)\\n\\n===Mixtapes===\\n*\\'\\'Bi-polar Disc One\\'\\' (2010)\\n*\\'\\'Bi-polar Disc Two\\'\\' (2010)\\n*\\'\\'Bi-polar 3\\'\\' (2011)\\n*\\'\\'Bi-polar 4\\'\\' (2011)\\n*\\'\\'Money, Powder, Regrets\\'\\' (2012)\\n*\\'\\'Everybody Weak\\'\\' (2012)\\n*\\'\\'Purple Summer\\'\\' (2016)\\n*\\'\\'Purple Summer 2: Sun Don\\'t Shine\\'\\' (2016)\\n*\\'\\'Purple Summer 03: Purple Hearted Soldier\\'\\' (2017)\\n*\\'\\'First Night Out\\'\\' (2017)\\n*\\'\\'Money Changes Everything\\'\\' (2017)\\n*\\'\\'The Wolf of Grape Street\\'\\' (2018)\\n*\\'\\'Free 03\\'\\' (with [[Mike Free]]) (2023)\\n\\n===Extended plays===\\n*\\'\\'Porter 2 Grape\\'\\' with [[Nef the Pharaoh]] (2018)\\n*\\'\\'Meet the Drummers\\'\\' with [[Travis Barker]] (2019)\\n*\\'\\'03 Inna Key\\'\\' (2021)\\n\\n==References==\\n{{Reflist}}\\n\\n== External links ==\\n* [https://soundcloud.com/greedy-giddy Greedy Giddy Soundcloud]\\n* [https://soundcloud.com/03greedo 03 Greedo Soundcloud]\\n\\n{{Authority control}}\\n\\n[[Category:Rappers from Los Angeles]]\\n[[Category:1987 births]]\\n[[Category:Living people]]\\n[[Category:People from Watts, Los Angeles]]\\n[[Category:21st-century American rappers]]\\n[[Category:West Coast hip hop musicians]]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pageid = list(wiki['03 Greedo']['query']['pages'].keys())[0]\n",
    "wiki['03 Greedo']['query']['pages'][pageid]['revisions'][0]['*']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part B: Building the networks\n",
    "\n",
    "Now, we're going to build one huge NetworkX directed graph, which includes both West-coast and East-coast rappers. \n",
    "\n",
    "The nodes in the network will be all the rappers, and we will place an edge between nodes $A$ and $B$ if the Wikipedia page of node $A$ links to the Wikipedia page of node $B$.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "> ***Video instructions:*** Getting started with rap music. Link: https://www.dropbox.com/scl/fi/ivd99y7tfeqpzj9lxgh0p/GettingStartedWithRapMusic.mp4?rlkey=6y3ye8iex6ogcy93jzyviqlej&dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> \n",
    "> _Exercise_: Build the network of rappers \n",
    "\n",
    "> Now we can build the network. Isn't this a little bit cool? What a dataset :)\n",
    "\n",
    "> The overall strategy for this is the following: \n",
    "> Take the pages you have downloaded for each rappers. \n",
    "> Each page corresponds to a rapper, which is a node in your network. \n",
    "> Find all the hyperlinks in a rapper's page that link to another node of the network (e.g. an other character). \n",
    "> There are many ways to do this, but below, I've tried to break it down into natural steps. \n",
    "> Keep in mind that the network should include **both** West-coast and East-coast rappers (and that it is possible that some West-coast rappers will have links to East-coast rappers and vice-versa).\n",
    "> \n",
    "> **Note**: When you add a node to the network, also include an `attribute` (i.e. that specifies the universe where the character comes from; either West coast, or East coast)\n",
    ">\n",
    ">\n",
    "> * Use a regular expression to extract all outgoing links from each of the pages you downloaded above. \n",
    "> * For each link you extract, check if the target is a rapper. If yes, keep it. If no, discard it.\n",
    "> * Use a NetworkX [`DiGraph`](https://networkx.github.io/documentation/development/reference/classes.digraph.html) to store the network. Store also the properties of the nodes (i.e. which coast they represent).\n",
    "> * When have you finished, you'll notice that some nodes do not have any out- or in- degrees. You may *discard* those from the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> *Exercise*: Simple network statistics and analysis\n",
    "\n",
    "> * What is the number of nodes in the network? \n",
    "> * More importantly, what is the number of links?\n",
    "> * What is the number of links connecting West coast and East coast? What do those links mean?\n",
    "> * Plot the in and out-degree distributions. What do you observe? Can you explain why the in-degree distribution is different from the out-degree distribution?\n",
    ">     * Compare the degree distribution to a *random network* with the same number of nodes and *p*\n",
    ">     * Compare the degree distribution to a *scale-free* network with the same number of nodes.\n",
    "> * Who are top 10 most connected rappers? (Report results for in-degrees and out-degrees). Comment on your findings. Is this what you would have expected?\n",
    "> * Who are the top 5 most connected West coast rappers (again in terms of both in/out-degree)?\n",
    "> * Who are the top 5 most connected East coast rappers (again in terms of both in/out-degree)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The total degree distribution (in + out degree) for you network should resemble the distribution displayed on the image below:\n",
    "![img](https://github.com/SocialComplexityLab/socialgraphs2023/blob/main/files/WestcoastvsEastcoast_degrees.png?raw=true)\n",
    "![img](https://github.com/SocialComplexityLab/socialgraphs2023/blob/main/files/WestcoastvsEastcoast_degrees_loglog.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
